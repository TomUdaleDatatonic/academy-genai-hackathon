{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11f2b9b-3568-4449-8d26-28823ec9f650",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1963fb-ae5a-4397-bc4e-cadc59db7af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sqlalchemy-bigquery langchain-experimental==0.0.17 langchain==0.0.240 pydantic==1.10.12 gradio==3.44.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de8118a-68c6-4ed5-85b7-9adb6b90ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f26207-ec2c-4302-a42d-133b77e34bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"PROJECT_ID\"\n",
    "GOOGLE_APPLICATION_CREDENTIALS = \"../credentials.json\"\n",
    "SERVICE_ACCOUNT = \"SERVICE_ACCOUNT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1713df-ee31-4885-b0f7-d6bd230a39a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud config set account {SERVICE_ACCOUNT}\n",
    "!gcloud auth activate-service-account --key-file={GOOGLE_APPLICATION_CREDENTIALS}\n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bb258-fff2-440a-9017-90ecaab9fc46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52836233-71a2-4614-93ba-b946a1dd1ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddb12a-03dd-4aaa-bd51-23fe4750ef89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8ac9d-fa40-4d5e-bfab-4e0901fa956b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = VertexAI(model_name='text-bison@001',\n",
    "               temperature=0, max_output_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153878f7-75ee-49b6-aa7d-bed2c9695f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm(\"tell me a story about mice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8190691-0a1a-4515-bfbe-eec1a8e14992",
   "metadata": {},
   "source": [
    "## Setup DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d589b1-3ee6-4e15-b0a1-32b36f5b0045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65eac44-3e6f-4626-acfb-7f462a1fa083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langchain_db = SQLDatabase.from_uri(f\"bigquery://{PROJECT_ID}/hackathon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a15a1e6-ce09-400f-b5b5-cddae2f5b0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langchain_db.run(\"SELECT count(*) FROM orders WHERE order_date BETWEEN '2023-01-01' AND '2023-01-31'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a351a2-5cbb-4dca-bfd6-8a07148b1f1a",
   "metadata": {},
   "source": [
    "## Create Langchain SQL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efd87d-bb9a-4d7b-a7b8-72002cd6d81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SQLDatabaseSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c8a27-c8b8-4422-b6be-3cddb5a45cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseSequentialChain.from_llm(\n",
    "        llm,\n",
    "        langchain_db,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079c102-2340-496f-9d25-afdb19b36b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = db_chain(\"how many items did I sell in January 2023\")\n",
    "output[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0085b-b030-45b9-8b39-35fa0a4c811f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output[\"intermediate_steps\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245043d-c7ea-4487-b679-8a6e20435a4c",
   "metadata": {},
   "source": [
    "## Improving The Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c0e8d-404b-4c99-8c60-da29f2be2923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73a71d-0af5-4bf8-a2a8-a0bc7a11b500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CUSTOM_SQL_PROMPT = \"\"\"\n",
    "You are a GoogleSQL expert. Given an input question, first create a syntactically\n",
    "correct GoogleSQL query to run, then look at the results of the query and return\n",
    "the answer to the input question.\n",
    "\n",
    "Unless the user specifies in the question a specific number of examples to obtain,\n",
    "query for at most {top_k} results using the LIMIT clause as per GoogleSQL. You can\n",
    "order the results to return the most informative data in the database.\n",
    "\n",
    "Never query for all columns from a table. You must query only the columns that are\n",
    "needed to answer the question. Wrap each column name and value in backticks (`)\n",
    "to denote them as delimited identifiers.\n",
    "\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful\n",
    "to not query for columns that do not exist. Also, pay attention to which column\n",
    "is in which table.\n",
    "\n",
    "Name all columns in the returned data appropriately. If a column does not have a\n",
    "matching name in the schema, create an appropriate name reflecting its content.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "\n",
    "Today''s date is {today_date}. When querying between dates, add the dates in quotes\n",
    "('')\n",
    "\n",
    "If someone asks for a specific month, use the range between the current month''s\n",
    "start date and the current month''s end date.\n",
    "\n",
    "If someone asks for a specific year, use the range between the first month of the\n",
    "current year and the current month''s end date.\n",
    "\n",
    "\n",
    "Remember to always use natural language when writing your final answer.\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923efca7-9f30-4350-ab0e-e5a32a11a42c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prompt = PromptTemplate(template=CUSTOM_SQL_PROMPT, input_variables=[\"question\", \"table_info\", \"today_date\", \"top_k\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761ec83-85ff-4e02-a9c4-a1807ba621e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = db_chain(test_prompt.format(\n",
    "    question = \"how many items did I sell in January 2023\",\n",
    "    table_info = [\"customers\",\"employees\",\"financial_goals\",\"inventory\",\"orders\",\"product_reviews\",\"supplier_orders\"],\n",
    "    today_date = datetime.now().strftime(\"%m/%d/%Y\"),\n",
    "    top_k=10\n",
    "))\n",
    "output[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94887d-e32c-46d1-858a-faede57ea738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "table_names = [\"customers\",\"employees\",\"financial_goals\",\"inventory\",\"orders\",\"product_reviews\",\"supplier_orders\"]\n",
    "\n",
    "def create_sql_chain(question: str, table_info: str = table_names, top_k:int=100, llm: VertexAI = llm, db=langchain_db):\n",
    "    \"\"\" Create a Q&A conversation chain using the VertexAI LLM.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    db_chain = SQLDatabaseSequentialChain.from_llm(\n",
    "        llm,\n",
    "        db,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "    )\n",
    "    test_prompt = PromptTemplate(template=CUSTOM_SQL_PROMPT, input_variables=[\"question\", \"table_info\", \"today_date\", \"top_k\"])\n",
    "\n",
    "    today_date = datetime.now().strftime(\"%m/%d/%Y\")\n",
    "    output = db_chain(test_prompt.format(\n",
    "        question=question,\n",
    "        table_info=table_info,\n",
    "        today_date=today_date,\n",
    "        top_k=top_k\n",
    "        ))\n",
    "    sql_query = output[\"intermediate_steps\"][1]\n",
    "    response = output[\"result\"]\n",
    "    \n",
    "    return response, sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d3021-c2b9-498a-9e6a-7fc465228489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_sql_chain('how many items did I sell in January?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2252d4-4b36-43dd-8fd0-0598eae7c8e1",
   "metadata": {},
   "source": [
    "## Chaining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19c193-0127-448a-b3f7-1e9fb45b7317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37401c41-4fea-4194-a375-4c92f5466c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMAIL_PROMPT = \"\"\"You are an Analytics Assistant. Your task is to assist users to better understand the insights from their BigQuery datasets.\n",
    "Users will ask a question to BigQuery and you will receive the question and the answer. \n",
    "\n",
    "Your task is to draft an email summarising the answer provided to the user.\n",
    "\n",
    "The user question was:\n",
    "```\n",
    "{question}\n",
    "```\n",
    "and the answer provided was \n",
    "```\n",
    "{answer}\n",
    "```\n",
    "\n",
    "Based on this, draft an email. Structure the email as follows:\n",
    "1. Start with a cordial introduction\n",
    "2. Remind the recipient as to what the user question was\n",
    "3. Provide a summary of the answer\n",
    "4. Send your best regards and say that you are happy to have a follow up\n",
    "\n",
    "Answer here:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "email_prompt = PromptTemplate(template=EMAIL_PROMPT, input_variables=[\"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688c49a-81a9-401c-9be3-1c788b09eee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "email_chain = LLMChain(\n",
    "        llm=llm, prompt=email_prompt, output_key=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece353a-7f77-4b0f-924f-cb5b704f611d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(Markdown(email_chain.run(\n",
    "    {\n",
    "        'question':\"what is the meaning of life?\", \n",
    "        'answer': \"42\"\n",
    "    }\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a53ed-09ba-47e5-a8a2-95b1b1fe5081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combined_chain(\n",
    "    question: str, \n",
    "    table_info: str = table_names, \n",
    "    top_k:int=100, \n",
    "    llm: VertexAI = llm, \n",
    "    db=langchain_db\n",
    "):\n",
    "    response, sql_query = create_sql_chain(\n",
    "        question,\n",
    "        table_info,\n",
    "        top_k,\n",
    "        llm,\n",
    "        db\n",
    "    )\n",
    "    \n",
    "    output = email_chain.run(\n",
    "        {\n",
    "            'question':question,\n",
    "            'answer':response\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8e335-a8cb-4668-8929-328782f51e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(Markdown(combined_chain(\"how many items did I sell in January 2023\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830dfbc3-c498-41fe-8e3a-1923cdfd3d08",
   "metadata": {},
   "source": [
    "## Grad IO email interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2837c26-cc19-4266-8b8e-b2eab2dbd2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e3d88-4bc5-497b-8da0-9f646750ffe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn= combined_chain,  # Function to execute when a query is received\n",
    "    inputs=\"text\",      # Input is a single text field\n",
    "    outputs=\"text\",     # Output will be a text response\n",
    "    title=\"Analytics Worker Demo\",\n",
    "    description=\"Enter a question, and the system will query the database and provide an answer.\",\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface on a specified port (e.g., 5000)\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
